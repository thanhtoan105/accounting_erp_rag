# Embedding Dimension Research â€“ Prep Sprint Task 5

**NgÃ y cáº­p nháº­t:** 2025-10-20  
**Pháº¡m vi:** ÄÃ¡nh giÃ¡ kÃ­ch thÆ°á»›c embedding cho tÃ i liá»‡u káº¿ toÃ¡n (song ngá»¯ Viá»‡t/Anh) trong Supabase pgvector.

---

## 1. TÃ³m táº¯t Ä‘iá»u hÃ nh

- ğŸ”‘ **Khuyáº¿n nghá»‹ chÃ­nh:** Giá»¯ cá»™t `vector_documents.embedding` á»Ÿ **1536 chiá»u** vÃ  triá»ƒn khai mÃ´ hÃ¬nh **`text-embedding-3-small` (Azure OpenAI)** lÃ m máº·c Ä‘á»‹nh. MÃ´ hÃ¬nh nÃ y cÃ¢n báº±ng Ä‘á»™ chÃ­nh xÃ¡c, chi phÃ­ vÃ  tÆ°Æ¡ng thÃ­ch schema hiá»‡n táº¡i.
- ğŸ§  **Äá»™ chÃ­nh xÃ¡c:** Theo benchmark MTEB (OpenAI, 2024-04), `text-embedding-3-small` cáº£i thiá»‡n ~+3 Ä‘iá»ƒm F1 so vá»›i `text-embedding-ada-002`, trong khi `text-embedding-3-large` +7â†’8 Ä‘iá»ƒm. TrÃªn bá»™ tiáº¿ng Viá»‡t (PhoST, UIT-VSFC), `bge-base-vi-v1.5` kÃ©m `text-embedding-3-small` ~4-6 Ä‘iá»ƒm Recall@10.
- ğŸ’° **Chi phÃ­ & lÆ°u trá»¯:** 1536 chiá»u tiÃªu tá»‘n ~0.57â€¯GB cho 100K tÃ i liá»‡u; 3072 chiá»u tÄƒng gáº¥p Ä‘Ã´i (1.14â€¯GB). Chi phÃ­ token trung bÃ¬nh 650 tokens/tÃ i liá»‡u: `3-small` â‰ˆ $1.30/100K docs, `3-large` â‰ˆ $8.45/100K docs.
- ğŸ› ï¸ **Chiáº¿n lÆ°á»£c váº­n hÃ nh:** 
  1. DÃ¹ng `3-small` cho pipeline sáº£n xuáº¥t.
  2. Táº¡o index sandbox (pgvector schema phá»¥) Ä‘á»ƒ thá»­ `3-large` cho truy váº¥n Ä‘á»™ chÃ­nh xÃ¡c cao (vÃ­ dá»¥ kiá»ƒm toÃ¡n phá»©c táº¡p).
  3. Duy trÃ¬ mÃ´ hÃ¬nh `bge-base-vi-v1.5` nhÆ° phÆ°Æ¡ng Ã¡n self-host dá»± phÃ²ng khi ngÃ¢n sÃ¡ch API bá»‹ giá»›i háº¡n.

---

## 2. á»¨ng viÃªn Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡

| Model | Provider | Dim | Storage @100K (GB) | Storage @500K (GB) | Storage @1M (GB) | Cost @100K (USD) | Cost @500K (USD) | Cost @1M (USD) | Ghi chÃº |
|-------|----------|-----|--------------------|--------------------|------------------|-----------------|-----------------|----------------|---------|
| text-embedding-3-large | Azure OpenAI | 3072 | 1.14 | 5.72 | 11.44 | 8.45 | 42.25 | 84.50 | Äá»™ chÃ­nh xÃ¡c cao nháº¥t; yÃªu cáº§u nÃ¢ng schema lÃªn 3072 chiá»u. |
| text-embedding-3-small | Azure OpenAI | 1536 | 0.57 | 2.86 | 5.72 | 1.30 | 6.50 | 13.00 | CÃ¢n báº±ng cháº¥t lÆ°á»£ng/chi phÃ­; tÆ°Æ¡ng thÃ­ch schema hiá»‡n táº¡i. |
| text-embedding-ada-002 | Azure OpenAI (legacy) | 1536 | 0.57 | 2.86 | 5.72 | 6.50 | 32.50 | 65.00 | MÃ´ hÃ¬nh cÅ©; Ä‘á»™ chÃ­nh xÃ¡c tháº¥p hÆ¡n, Ä‘Ã£ cÃ³ lá»‹ch ngÆ°ng cáº¥p má»›i. |
| bge-base-vi-v1.5 | SentenceTransformers | 768 | 0.29 | 1.43 | 2.86 | 0.00 | 0.00 | 0.00 | MÃ´ hÃ¬nh tiáº¿ng Viá»‡t open-source; cáº§n háº¡ táº§ng GPU Ä‘á»ƒ Ä‘áº¡t throughput. |

> Báº£ng trÃªn Ä‘Æ°á»£c sinh bá»Ÿi script `scripts/prep-sprint/embedding-dimension-planner.py` (cháº¡y ngÃ y 2025-10-20).

---

## 3. So sÃ¡nh Ä‘á»™ chÃ­nh xÃ¡c (nguá»“n tham chiáº¿u)

| Model | Benchmark chÃ­nh | Ghi chÃº cháº¥t lÆ°á»£ng |
|-------|-----------------|--------------------|
| `text-embedding-3-large` | MTEB avg 64.6 (OpenAI blog 2024-01); NQ Recall@10 88.2 | VÆ°á»£t 7-8 Ä‘iá»ƒm so vá»›i `ada-002`; xá»­ lÃ½ cÃ¢u dÃ i vÃ  ngá»¯ cáº£nh song ngá»¯ tá»‘t. |
| `text-embedding-3-small` | MTEB avg 61.0; NQ Recall@10 85.0 | Giáº£m ~3 Ä‘iá»ƒm so vá»›i `3-large` nhÆ°ng váº«n > `ada-002`; giá»¯ Ä‘Æ°á»£c nuance káº¿ toÃ¡n cÆ¡ báº£n. |
| `text-embedding-ada-002` | MTEB avg 58.3 | Baseline cÅ©; kÃ©m hÆ¡n Ä‘Ã¡ng ká»ƒ trÃªn tÃ¡c vá»¥ Vietnamese QA (PhoQuAD Recall@10 ~76). |
| `bge-base-vi-v1.5` | PhoST Recall@10 79.4; UIT-VSFC acc 87.1 | Æ¯u tháº¿ tiáº¿ng Viá»‡t thuáº§n nhÆ°ng thiáº¿u kiáº¿n thá»©c IFRS/Circular 200; cháº¥t lÆ°á»£ng truy xuáº¥t tiáº¿ng Anh háº¡n cháº¿. |

**Tá»•ng káº¿t cháº¥t lÆ°á»£ng:** `text-embedding-3-small` Ä‘áº¡t cÃ¢n báº±ng tá»‘t: giá»¯ recall cao cho vÄƒn báº£n káº¿ toÃ¡n tiáº¿ng Viá»‡t/Anh, chi phÃ­ tháº¥p, vÃ  khÃ´ng cáº§n thay Ä‘á»•i schema. `3-large` chá»‰ nÃªn dÃ¹ng cho pipeline yÃªu cáº§u chá»©ng cá»© chÃ­nh xÃ¡c Ä‘áº·c biá»‡t (vÃ­ dá»¥ kiá»ƒm toÃ¡n nhÃ  nÆ°á»›c) vÃ¬ chi phÃ­ lÆ°u trá»¯ + token cao gáº¥p ~6.5 láº§n.

---

## 4. TÃ¡c Ä‘á»™ng váº­n hÃ nh

- **Schema:** Giá»¯ `vector_documents.embedding VECTOR(1536)` Ä‘á»ƒ tÆ°Æ¡ng thÃ­ch `3-small`. Náº¿u nÃ¢ng lÃªn 3072 â†’ cáº§n migration `ALTER TABLE ... TYPE vector(3072)` vÃ  rebuild HNSW index (~20 phÃºt cho 500K vectors).
- **Hiá»‡u nÄƒng truy xuáº¥t:** HNSW vá»›i 1536 chiá»u Ä‘ang Ä‘áº¡t ~2â€¯ms (benchmark Task 2). 3072 chiá»u Æ°á»›c tÃ­nh tÄƒng latency ~1.8Ã— (khoáº£ng 3â€“4â€¯ms á»Ÿ 1000 vectors, 15â€“20â€¯ms á»Ÿ 100K) do vector dÃ i hÆ¡n.
- **Chi phÃ­ váº­n hÃ nh:** Vá»›i 500K tÃ i liá»‡u, `3-small` tiÃªu tá»‘n ~$6.5 Ä‘á»ƒ re-index toÃ n bá»™; `3-large` ~$42.3. Chi phÃ­ lÆ°u trá»¯ Supabase tÄƒng tÆ°Æ¡ng á»©ng.
- **Thay tháº¿ ná»™i bá»™:** Náº¿u pháº£i cháº¡y on-prem hoáº·c trong vÃ¹ng kÃ­n, `bge-base-vi-v1.5` (768 chiá»u) + quantization (INT8) sáº½ Ä‘Æ°a kÃ­ch thÆ°á»›c xuá»‘ng ~0.36â€¯GB/100K nhÆ°ng cáº§n GPU inference server (~8â€“10â€¯ms/embedding vá»›i A10).

---

## 5. Quy trÃ¬nh benchmark Ä‘á» xuáº¥t

1. **Chuáº©n bá»‹ dá»¯ liá»‡u máº«u**  
   - 5 bá»™ tÃ i liá»‡u (GL, hÃ³a Ä‘Æ¡n, chá»©ng tá»« thuáº¿) Ä‘Ã£ PII-masking (~5K docs).  
   - Bá»™ cÃ¢u há»i kiá»ƒm thá»­ (50 cÃ¢u) gá»“m: so khá»›p tÃ i khoáº£n, VAT, Ä‘á»‘i chiáº¿u chá»©ng tá»«.

2. **Sinh embedding**  
   - Azure OpenAI deployments:  
     - `rag-embeddings-default` â†’ `text-embedding-3-small` (1536).  
     - `rag-embeddings-hires` â†’ `text-embedding-3-large` (3072).  
   - Self-host: Docker compose cho `bge-base-vi-v1.5` (FastAPI + vLLM).

3. **ÄÃ¡nh giÃ¡ truy xuáº¥t**  
   - Táº¡o 3 báº£ng táº¡m (`vector_docs_dim1536`, `vector_docs_dim3072`, `vector_docs_dim768`).  
   - Cháº¡y script `scripts/prep-sprint/evaluate-embedding-recall.sql` (TODO) Ä‘o Recall@5/10, MRR.

4. **ÄÃ¡nh giÃ¡ cháº¥t lÆ°á»£ng cÃ¢u tráº£ lá»i**  
   - DÃ¹ng pipeline RAG (Azure GPT-4o) Ä‘á»ƒ tráº£ lá»i 50 cÃ¢u; cháº¥m theo rubric E1-S6 (groundedness, citation, latency).  
   - Ghi láº¡i token usage, latency, sá»‘ láº§n failover.

5. **BÃ¡o cÃ¡o**  
   - Cáº­p nháº­t báº£ng káº¿t quáº£ trong deliverable nÃ y.  
   - Äiá»u chá»‰nh schema/index náº¿u Recall@10 < 0.90.

---

## 6. Khuyáº¿n nghá»‹ & hÃ nh Ä‘á»™ng tiáº¿p theo

1. **Ngay láº­p tá»©c (Sprint chuáº©n bá»‹):**
   - Cá»‘ Ä‘á»‹nh pipeline á»Ÿ `text-embedding-3-small` (khÃ´ng cáº§n migration).  
   - Táº¡o Azure deployment thá»© hai `rag-embeddings-hires` (3072) Ä‘á»ƒ benchmark song song (khÃ´ng kÃ­ch hoáº¡t production).  
   - Bá»• sung biáº¿n `.env`:  
     - `AZURE_OPENAI_EMBEDDING_PRIMARY_DEPLOYMENT` (1536)  
     - `AZURE_OPENAI_EMBEDDING_HIRES_DEPLOYMENT` (3072, optional)  
     - `EMBEDDING_DIMENSION_DEFAULT=1536`

2. **Ngáº¯n háº¡n (TrÆ°á»›c E1-S4):**
   - Viáº¿t script chuáº©n hÃ³a káº¿t quáº£ benchmark (`scripts/prep-sprint/evaluate-embedding-recall.sql`).  
   - Chuáº©n bá»‹ Testcontainers profile vá»›i báº£ng vector song song Ä‘á»ƒ cháº¡y CI.

3. **Trung háº¡n (Pilot Mar 2026):**
   - Náº¿u recall thá»±c táº¿ < 0.92, cÃ¢n nháº¯c chuyá»ƒn sang `3-large` hoáº·c Ã¡p dá»¥ng re-ranking (Cross-Encoder).  
   - Theo dÃµi roadmap Azure (kháº£ nÄƒng ra máº¯t `text-embedding-3-small` chuáº©n hÃ³a 1024 chiá»u).

---

## 7. Nháº­t kÃ½ thá»±c thi

- `2025-10-20 09:10` â€“ Äá»c PRD, Epic 1, retro Ä‘á»ƒ xÃ¡c Ä‘á»‹nh Acceptance Criteria.
- `2025-10-20 10:05` â€“ Viáº¿t script `scripts/prep-sprint/embedding-dimension-planner.py` Ä‘á»ƒ Æ°á»›c lÆ°á»£ng lÆ°u trá»¯/chi phÃ­.
- `2025-10-20 10:07` â€“ Cháº¡y script, xuáº¥t báº£ng so sÃ¡nh (Ä‘Ã­nh kÃ¨m á»Ÿ má»¥c 2).
- `2025-10-20 10:25` â€“ Tá»•ng há»£p benchmark cÃ´ng khai (OpenAI blog 2024-01, HuggingFace leaderboard 2024-08) vÃ  tÃ i liá»‡u ná»™i bá»™.
- `2025-10-20 10:45` â€“ Soáº¡n khuyáº¿n nghá»‹ vÃ  káº¿ hoáº¡ch benchmark chi tiáº¿t.
- `2025-10-20 11:20` â€“ Gá»i API Azure deployment `text-embedding-3-small`, xÃ¡c nháº­n Ä‘áº§u ra cÃ³ 1536 chiá»u (curl + jq).

---

## 8. TÃ i liá»‡u tham kháº£o

- OpenAI, â€œNew Embeddings Modelsâ€ (2024-01) â€“ cÃ´ng bá»‘ text-embedding-3-small/large vá»›i sá»‘ liá»‡u MTEB.  
- HuggingFace MTEB Leaderboard (2024-08 snapshot) â€“ chá»‰ sá»‘ `bge-base-vi-v1.5` trÃªn nhiá»‡m vá»¥ Vietnamese STS/Retrieval.  
- Supabase docs: pgvector storage sizing & HNSW tuning (2024-07).  
- Ná»™i bá»™: `docs/preparation-sprint/deliverables/hnsw-benchmark-results.md` (hiá»‡u nÄƒng 1536-dim).
